---
layout: post
bigtitle: "[Computer Vision] - LeNet-5"
subtitle: "Computer Vision, CNN, Classification"
categories:
    - AI
    - papers
# tags:
#   - python
#   - programming language
#   - basic
comments: true
# related_posts:
#    -
#    - 
published: true
---


## CNN/Classification - LeNet-5

---
이번 포스트에서는 최초의 Convolutional Neural Networks인 LeNet-5에 대해 알아보겠습니다.

참고 논문 : [LeNet-5](/assests/paper/LeNet-5_1998.pdf)

## Explanation
- 딥러닝으로 시작한 최초의 CNN(Convolutional Neural Networks)
- 세계 4대 인공지능 대가인 얀 르쿤(Yann LeCun), 요슈아 벤지오(Yoshua Bengio) 개발
- 1989년부터 개발을 시작해서 1998년에 LeNet-5까지 발전
    - 참조 : [Wikipedia](https://en.wikipedia.org/wiki/LeNet)
- 데이터셋 : 흑백 MNIST 손글씨 데이터 셋 사용(GrayScale)
    - Image Size : 28 x 28
    - Labeling : 0~9
    - Train : 60,000장
    - Test : 10,000장

## Contents
여기서는 일단 모델 레이어의 구조 및 역할을 알아보겠습니다.

총 논문의 내용은 따로 추가해서 올리겠습니다.

본문 내용 위치 :
> 2. CONVOLUTIONAL NEURAL NETWORKS FOR ISOLATED CHARACTER RECOGNITION - B. LeNet-5


- Datasets : MNIST
    - 1채널의 32x32의 손글씨 이미지(0~9 Labeling)
    - GrayScale
    - Train : 60,000장, Test : 10,000장

- 32x32 이미지를 쓴 이유
    - 잠재적 구별적 특징(끝점, 코너...)이 가장 높은 수준의 특징 검출기의 수용 필드(Receptive Fields)의 중앙에 나타날 수 있게 하는 것이 바람직함

- 정규화(Normalization) 사용
    - 입력의 픽셀 값은 배경은 -0.1, 전경은 1.175
    - 평균 입력 대략 N(0,1)로 맞춤 --> 학습 속도 빠르게 하기 위함

LeNet-5의 구조는 다음과 같습니다.

![LeNet-5 Model Layer Structure](/assets/img/AI/papers/LeNet-5_layers.png)

- 총 7개의 Layers(Input layers 제외)
    - 3개의 Convolutional Layers와 2개의 Average Pooling Layers, 2개의 Fully Connected Layers

- C : Convolutional Layers, S : Subsampling Layers, F : Fully-Connected Layers

**Feature Maps 크기 계산 및 파라미터 연결 개수 계산은 다음 게시물 확인**

- C1 
    - 28x28x6 = 28x28 크기의 6개의 Feature Maps
    - 5x5 filter 사용
    - 156개의 학습 파라미터, 122,304의 연결
    - Channels 6, Kernel Size 5, stride 1, padding 0

- S2 = Average Pooling
    - 14x14x6 = 14x14 크기의 6개의 Feature Maps
    - 2x2 filter 사용
    - 12개의 학습 파라미터, 5,880개의 연결
    - Channels 6, Kernel Size 2, stride 2

- C3
    - 10x10x16 = 10x10 크기의 16개의 Feature Maps
    - 5x5 filter 사용
    - 1,516개의 학습 파라미터, 151,600개의 연결
    - Channels 16, Kernel Size 5, stride 1, padding 0

- S4 = Average Pooling
    - 5x5x16 = 5x5 크기의 16개의 Feature Maps
    - 2x2 filter 사용
    - 32개의 학습 파라미터, 2,000개의 연결
    - Channels 16, Kernel Size 2, stride 2

- C5
    - 1x1x120 = 1x1 크기의 120개의 Feature Maps
    - 5x5 filter 사용
    - 48,120개의 학습 파라미터 연결
    - 사실상 Flatten과 같은 역할

- F6
    - 120 -> 84 개로 Fully Connected 연결
    - 10,164개의 학습 파라미터 연결

- output(F7)
    - 84 -> 10 개로 Fully Connected 연결
    - 850개의 학습 파라미터 연결
    - 10개로 압축 시 squashing function(activation function) 사용
    - squashing function : tanh
    
